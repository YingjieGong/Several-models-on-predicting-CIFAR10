{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from skimage import feature, color\n",
    "from sklearn import preprocessing\n",
    "from cvxopt import matrix, solvers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step\n",
      "Training features shape: (50000, 512)\n",
      "Testing features shape: (10000, 512)\n"
     ]
    }
   ],
   "source": [
    "# load cifar10 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalize data\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# extract features\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "features_train = model.predict(x_train)\n",
    "features_test = model.predict(x_test)\n",
    "\n",
    "# reshape features\n",
    "features_train = features_train.reshape(features_train.shape[0], -1)\n",
    "features_test = features_test.reshape(features_test.shape[0], -1)\n",
    "\n",
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "features_test = scaler.transform(features_test)\n",
    "\n",
    "print(\"Training features shape:\", features_train.shape)\n",
    "print(\"Testing features shape:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(y_true, y_pred):\n",
    "    return np.maximum(0, 1 - y_true * y_pred).mean()\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return (y_true == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVM:\n",
    "    def __init__(self, kernel='linear', C=1.0):\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.alpha = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.b = 0\n",
    "\n",
    "    def kernel_function(self, x, y):\n",
    "        if self.kernel == 'linear':\n",
    "            return np.dot(x, y)\n",
    "        elif self.kernel == 'polynomial':\n",
    "            return (1 + np.dot(x, y)) ** 3\n",
    "        elif self.kernel == 'rbf':\n",
    "            sigma = 1.0\n",
    "            return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown kernel function.\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y = y.reshape(-1, 1) * 1.0\n",
    "        X_dash = y * X\n",
    "        H = np.dot(X_dash , X_dash.T) * 1.\n",
    "\n",
    "        # Convert into cvxopt format\n",
    "        P = matrix(H)\n",
    "        q = matrix(-np.ones((n_samples, 1)))\n",
    "        G = matrix(np.vstack((np.eye(n_samples)*-1,np.eye(n_samples))))\n",
    "        h = matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * self.C)))\n",
    "        A = matrix(y.reshape(1, -1))\n",
    "        b = matrix(np.zeros(1))\n",
    "\n",
    "        # Solve QP problem\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Extract support vectors\n",
    "        alphas = np.array(solution['x'])\n",
    "        self.alpha = alphas[alphas > 1e-4].flatten()\n",
    "        sv = alphas > 1e-4\n",
    "        ind = np.where(sv)[0]\n",
    "        self.support_vectors = X[ind]\n",
    "        self.support_vector_labels = y[ind]\n",
    "        self.b = np.mean(y[ind] - np.dot(self.support_vectors, self.support_vectors.T).dot(alphas[sv] * y[sv]))\n",
    "        \n",
    "        # Calculate the predictions on the training set\n",
    "        y_pred = self.predict(X)\n",
    "        # Convert predictions back to original class labels\n",
    "        y_pred = np.where(y_pred < 0, -1, 1)\n",
    "        y = np.where(y <= 0, -1, 1)  # Ensure y is in {-1, 1}\n",
    "        \n",
    "        # Calculate the loss and accuracy\n",
    "        loss = hinge_loss(y, y_pred)\n",
    "        acc = accuracy(y, y_pred)\n",
    "        \n",
    "        return loss, acc\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_predict = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            prediction = 0\n",
    "            for alpha, sv_y, sv in zip(self.alpha, self.support_vector_labels, self.support_vectors):\n",
    "                prediction += alpha * sv_y * self.kernel_function(X[i], sv)\n",
    "            prediction += self.b\n",
    "            y_predict[i] = np.sign(prediction).item()\n",
    "        return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for class 0...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0634e+03 -2.5220e+04  2e+05  3e+00  4e-12\n",
      " 1: -1.3639e+03 -1.5721e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.1957e+03 -7.2551e+03  1e+04  1e-01  2e-12\n",
      " 3: -1.1246e+03 -4.7236e+03  5e+03  6e-02  2e-12\n",
      " 4: -1.0907e+03 -3.5638e+03  4e+03  4e-02  2e-12\n",
      " 5: -1.0840e+03 -3.1660e+03  3e+03  3e-02  2e-12\n",
      " 6: -1.0381e+03 -2.8883e+03  2e+03  2e-02  2e-12\n",
      " 7: -1.0712e+03 -2.0447e+03  1e+03  7e-03  2e-12\n",
      " 8: -1.1042e+03 -1.6416e+03  6e+02  2e-03  2e-12\n",
      " 9: -1.1290e+03 -1.4744e+03  4e+02  8e-04  2e-12\n",
      "10: -1.1488e+03 -1.3970e+03  3e+02  5e-04  2e-12\n",
      "11: -1.1655e+03 -1.3310e+03  2e+02  1e-04  2e-12\n",
      "12: -1.1831e+03 -1.2879e+03  1e+02  6e-05  2e-12\n",
      "13: -1.1937e+03 -1.2652e+03  7e+01  3e-05  2e-12\n",
      "14: -1.2039e+03 -1.2459e+03  4e+01  1e-05  2e-12\n",
      "15: -1.2077e+03 -1.2373e+03  3e+01  5e-06  2e-12\n",
      "16: -1.2125e+03 -1.2299e+03  2e+01  2e-06  2e-12\n",
      "17: -1.2151e+03 -1.2260e+03  1e+01  6e-07  2e-12\n",
      "18: -1.2173e+03 -1.2231e+03  6e+00  2e-07  2e-12\n",
      "19: -1.2186e+03 -1.2215e+03  3e+00  6e-08  2e-12\n",
      "20: -1.2193e+03 -1.2207e+03  1e+00  2e-08  2e-12\n",
      "21: -1.2196e+03 -1.2203e+03  7e-01  7e-09  2e-12\n",
      "22: -1.2198e+03 -1.2200e+03  2e-01  9e-10  2e-12\n",
      "23: -1.2199e+03 -1.2199e+03  5e-02  3e-14  2e-12\n",
      "24: -1.2199e+03 -1.2199e+03  1e-02  1e-14  3e-12\n",
      "25: -1.2199e+03 -1.2199e+03  8e-04  3e-15  2e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3461, Training Accuracy: 0.8270\n",
      "Training model for class 1...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1750e+03 -2.4552e+04  1e+05  3e+00  3e-12\n",
      " 1: -1.4853e+03 -1.5989e+04  3e+04  6e-01  3e-12\n",
      " 2: -1.2639e+03 -7.8041e+03  1e+04  2e-01  2e-12\n",
      " 3: -1.1811e+03 -4.7936e+03  6e+03  8e-02  2e-12\n",
      " 4: -1.1434e+03 -3.6339e+03  4e+03  4e-02  2e-12\n",
      " 5: -1.1338e+03 -2.6252e+03  2e+03  2e-02  2e-12\n",
      " 6: -1.1400e+03 -2.1621e+03  1e+03  1e-02  2e-12\n",
      " 7: -1.1640e+03 -1.8212e+03  8e+02  6e-03  2e-12\n",
      " 8: -1.1881e+03 -1.5904e+03  5e+02  3e-03  2e-12\n",
      " 9: -1.2101e+03 -1.4659e+03  3e+02  1e-03  2e-12\n",
      "10: -1.2256e+03 -1.3980e+03  2e+02  6e-04  2e-12\n",
      "11: -1.2374e+03 -1.3596e+03  1e+02  3e-04  2e-12\n",
      "12: -1.2497e+03 -1.3273e+03  8e+01  2e-04  2e-12\n",
      "13: -1.2592e+03 -1.3044e+03  5e+01  6e-05  2e-12\n",
      "14: -1.2646e+03 -1.2933e+03  3e+01  3e-05  2e-12\n",
      "15: -1.2689e+03 -1.2855e+03  2e+01  9e-06  2e-12\n",
      "16: -1.2720e+03 -1.2808e+03  9e+00  3e-06  2e-12\n",
      "17: -1.2738e+03 -1.2783e+03  5e+00  1e-06  2e-12\n",
      "18: -1.2751e+03 -1.2767e+03  2e+00  2e-07  2e-12\n",
      "19: -1.2754e+03 -1.2762e+03  8e-01  8e-08  2e-12\n",
      "20: -1.2757e+03 -1.2759e+03  3e-01  1e-08  2e-12\n",
      "21: -1.2758e+03 -1.2758e+03  6e-02  3e-09  2e-12\n",
      "22: -1.2758e+03 -1.2758e+03  9e-03  2e-10  2e-12\n",
      "23: -1.2758e+03 -1.2758e+03  4e-04  7e-12  3e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3559, Training Accuracy: 0.8221\n",
      "Training model for class 2...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7781e+03 -2.5083e+04  1e+05  3e+00  4e-12\n",
      " 1: -1.8494e+03 -1.6015e+04  3e+04  4e-01  4e-12\n",
      " 2: -1.6389e+03 -9.0880e+03  1e+04  2e-01  2e-12\n",
      " 3: -1.5830e+03 -5.6195e+03  6e+03  7e-02  2e-12\n",
      " 4: -1.5947e+03 -3.6817e+03  3e+03  3e-02  2e-12\n",
      " 5: -1.6319e+03 -2.9530e+03  2e+03  1e-02  2e-12\n",
      " 6: -1.6910e+03 -2.4452e+03  9e+02  6e-03  2e-12\n",
      " 7: -1.7231e+03 -2.2222e+03  5e+02  3e-03  2e-12\n",
      " 8: -1.7471e+03 -2.1086e+03  4e+02  1e-03  2e-12\n",
      " 9: -1.7698e+03 -2.0333e+03  3e+02  8e-04  2e-12\n",
      "10: -1.7861e+03 -1.9692e+03  2e+02  2e-04  3e-12\n",
      "11: -1.7981e+03 -1.9253e+03  1e+02  1e-14  3e-12\n",
      "12: -1.8183e+03 -1.8911e+03  7e+01  5e-15  3e-12\n",
      "13: -1.8277e+03 -1.8750e+03  5e+01  1e-14  3e-12\n",
      "14: -1.8359e+03 -1.8622e+03  3e+01  4e-14  3e-12\n",
      "15: -1.8411e+03 -1.8550e+03  1e+01  9e-15  3e-12\n",
      "16: -1.8438e+03 -1.8513e+03  8e+00  2e-14  3e-12\n",
      "17: -1.8453e+03 -1.8493e+03  4e+00  5e-15  3e-12\n",
      "18: -1.8462e+03 -1.8482e+03  2e+00  2e-14  3e-12\n",
      "19: -1.8467e+03 -1.8476e+03  8e-01  4e-14  3e-12\n",
      "20: -1.8470e+03 -1.8472e+03  2e-01  4e-14  3e-12\n",
      "21: -1.8471e+03 -1.8471e+03  8e-02  3e-14  3e-12\n",
      "22: -1.8471e+03 -1.8471e+03  2e-02  2e-15  3e-12\n",
      "23: -1.8471e+03 -1.8471e+03  1e-03  1e-14  3e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3265, Training Accuracy: 0.8368\n",
      "Training model for class 3...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6779e+03 -2.4495e+04  1e+05  3e+00  4e-12\n",
      " 1: -1.7816e+03 -1.5636e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.6005e+03 -7.2546e+03  9e+03  1e-01  3e-12\n",
      " 3: -1.5745e+03 -5.0492e+03  5e+03  6e-02  2e-12\n",
      " 4: -1.6076e+03 -3.3182e+03  2e+03  2e-02  2e-12\n",
      " 5: -1.6698e+03 -2.5369e+03  1e+03  1e-02  2e-12\n",
      " 6: -1.7017e+03 -2.2687e+03  6e+02  5e-03  2e-12\n",
      " 7: -1.7191e+03 -2.1311e+03  4e+02  2e-03  3e-12\n",
      " 8: -1.7397e+03 -2.0212e+03  3e+02  8e-04  3e-12\n",
      " 9: -1.7534e+03 -1.9734e+03  2e+02  4e-04  3e-12\n",
      "10: -1.7630e+03 -1.9320e+03  2e+02  7e-05  3e-12\n",
      "11: -1.7833e+03 -1.8860e+03  1e+02  3e-05  3e-12\n",
      "12: -1.7937e+03 -1.8667e+03  7e+01  1e-05  3e-12\n",
      "13: -1.8013e+03 -1.8520e+03  5e+01  6e-06  3e-12\n",
      "14: -1.8043e+03 -1.8446e+03  4e+01  2e-06  3e-12\n",
      "15: -1.8098e+03 -1.8358e+03  3e+01  1e-06  3e-12\n",
      "16: -1.8122e+03 -1.8317e+03  2e+01  6e-07  3e-12\n",
      "17: -1.8157e+03 -1.8268e+03  1e+01  3e-07  3e-12\n",
      "18: -1.8166e+03 -1.8252e+03  9e+00  1e-07  3e-12\n",
      "19: -1.8183e+03 -1.8230e+03  5e+00  5e-08  3e-12\n",
      "20: -1.8196e+03 -1.8214e+03  2e+00  1e-08  3e-12\n",
      "21: -1.8200e+03 -1.8209e+03  9e-01  5e-09  3e-12\n",
      "22: -1.8202e+03 -1.8206e+03  3e-01  1e-09  3e-12\n",
      "23: -1.8203e+03 -1.8205e+03  1e-01  4e-10  3e-12\n",
      "24: -1.8204e+03 -1.8204e+03  5e-02  1e-10  3e-12\n",
      "25: -1.8204e+03 -1.8204e+03  1e-02  1e-11  3e-12\n",
      "26: -1.8204e+03 -1.8204e+03  1e-03  1e-12  3e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.2976, Training Accuracy: 0.8512\n",
      "Training model for class 4...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6139e+03 -2.5375e+04  1e+05  3e+00  3e-12\n",
      " 1: -1.7447e+03 -1.6199e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.5709e+03 -7.8180e+03  1e+04  1e-01  2e-12\n",
      " 3: -1.5204e+03 -5.0815e+03  5e+03  6e-02  2e-12\n",
      " 4: -1.5341e+03 -3.6927e+03  3e+03  3e-02  2e-12\n",
      " 5: -1.5538e+03 -2.8662e+03  2e+03  2e-02  2e-12\n",
      " 6: -1.5560e+03 -2.5450e+03  1e+03  7e-03  2e-12\n",
      " 7: -1.6154e+03 -2.1552e+03  6e+02  3e-03  2e-12\n",
      " 8: -1.6401e+03 -2.0349e+03  4e+02  2e-03  2e-12\n",
      " 9: -1.6564e+03 -1.9434e+03  3e+02  6e-04  2e-12\n",
      "10: -1.6835e+03 -1.8627e+03  2e+02  3e-04  2e-12\n",
      "11: -1.7003e+03 -1.8156e+03  1e+02  1e-04  2e-12\n",
      "12: -1.7091e+03 -1.7922e+03  8e+01  5e-05  2e-12\n",
      "13: -1.7162e+03 -1.7786e+03  6e+01  3e-05  2e-12\n",
      "14: -1.7260e+03 -1.7593e+03  3e+01  4e-06  2e-12\n",
      "15: -1.7320e+03 -1.7504e+03  2e+01  1e-06  2e-12\n",
      "16: -1.7354e+03 -1.7455e+03  1e+01  5e-07  2e-12\n",
      "17: -1.7380e+03 -1.7420e+03  4e+00  7e-08  2e-12\n",
      "18: -1.7386e+03 -1.7413e+03  3e+00  2e-08  2e-12\n",
      "19: -1.7393e+03 -1.7404e+03  1e+00  4e-09  2e-12\n",
      "20: -1.7396e+03 -1.7401e+03  5e-01  7e-10  2e-12\n",
      "21: -1.7397e+03 -1.7399e+03  2e-01  1e-10  2e-12\n",
      "22: -1.7398e+03 -1.7398e+03  4e-02  2e-11  2e-12\n",
      "23: -1.7398e+03 -1.7398e+03  4e-03  4e-13  2e-12\n",
      "24: -1.7398e+03 -1.7398e+03  2e-04  4e-14  2e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3274, Training Accuracy: 0.8363\n",
      "Training model for class 5...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5789e+03 -2.3670e+04  1e+05  3e+00  3e-12\n",
      " 1: -1.7249e+03 -1.4958e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.5446e+03 -6.6847e+03  8e+03  1e-01  2e-12\n",
      " 3: -1.5144e+03 -4.4029e+03  4e+03  5e-02  2e-12\n",
      " 4: -1.5264e+03 -3.3440e+03  2e+03  3e-02  2e-12\n",
      " 5: -1.5513e+03 -2.7554e+03  2e+03  1e-02  2e-12\n",
      " 6: -1.5880e+03 -2.3246e+03  9e+02  7e-03  2e-12\n",
      " 7: -1.6248e+03 -2.0702e+03  5e+02  4e-03  2e-12\n",
      " 8: -1.6463e+03 -1.9382e+03  3e+02  2e-03  2e-12\n",
      " 9: -1.6607e+03 -1.8768e+03  2e+02  9e-04  2e-12\n",
      "10: -1.6822e+03 -1.8058e+03  1e+02  3e-04  2e-12\n",
      "11: -1.6960e+03 -1.7698e+03  8e+01  1e-04  2e-12\n",
      "12: -1.7056e+03 -1.7491e+03  4e+01  5e-05  2e-12\n",
      "13: -1.7114e+03 -1.7385e+03  3e+01  2e-05  2e-12\n",
      "14: -1.7160e+03 -1.7305e+03  1e+01  7e-06  2e-12\n",
      "15: -1.7185e+03 -1.7267e+03  8e+00  2e-06  2e-12\n",
      "16: -1.7205e+03 -1.7240e+03  3e+00  7e-07  2e-12\n",
      "17: -1.7215e+03 -1.7228e+03  1e+00  2e-07  2e-12\n",
      "18: -1.7218e+03 -1.7224e+03  5e-01  5e-08  2e-12\n",
      "19: -1.7220e+03 -1.7222e+03  3e-01  2e-08  2e-12\n",
      "20: -1.7220e+03 -1.7221e+03  8e-02  4e-09  2e-12\n",
      "21: -1.7221e+03 -1.7221e+03  2e-02  5e-10  3e-12\n",
      "22: -1.7221e+03 -1.7221e+03  9e-04  6e-14  3e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3377, Training Accuracy: 0.8311\n",
      "Training model for class 6...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1670e+03 -2.3897e+04  1e+05  3e+00  4e-12\n",
      " 1: -1.4583e+03 -1.4838e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.2701e+03 -7.4075e+03  1e+04  1e-01  2e-12\n",
      " 3: -1.1945e+03 -4.2611e+03  5e+03  6e-02  2e-12\n",
      " 4: -1.1602e+03 -3.1526e+03  3e+03  3e-02  2e-12\n",
      " 5: -1.1510e+03 -2.4262e+03  2e+03  2e-02  2e-12\n",
      " 6: -1.1580e+03 -1.9073e+03  1e+03  9e-03  2e-12\n",
      " 7: -1.1633e+03 -1.6779e+03  7e+02  5e-03  2e-12\n",
      " 8: -1.1777e+03 -1.4575e+03  3e+02  2e-03  2e-12\n",
      " 9: -1.1948e+03 -1.3501e+03  2e+02  7e-04  2e-12\n",
      "10: -1.2063e+03 -1.2982e+03  1e+02  2e-04  2e-12\n",
      "11: -1.2144e+03 -1.2710e+03  6e+01  7e-05  2e-12\n",
      "12: -1.2210e+03 -1.2564e+03  4e+01  2e-05  2e-12\n",
      "13: -1.2260e+03 -1.2487e+03  2e+01  9e-06  2e-12\n",
      "14: -1.2293e+03 -1.2436e+03  1e+01  4e-06  2e-12\n",
      "15: -1.2319e+03 -1.2398e+03  8e+00  9e-07  2e-12\n",
      "16: -1.2336e+03 -1.2377e+03  4e+00  4e-07  2e-12\n",
      "17: -1.2347e+03 -1.2363e+03  2e+00  8e-08  2e-12\n",
      "18: -1.2351e+03 -1.2358e+03  7e-01  2e-08  2e-12\n",
      "19: -1.2353e+03 -1.2355e+03  2e-01  4e-09  2e-12\n",
      "20: -1.2354e+03 -1.2355e+03  3e-02  9e-11  2e-12\n",
      "21: -1.2354e+03 -1.2354e+03  2e-03  7e-12  2e-12\n",
      "22: -1.2354e+03 -1.2354e+03  4e-05  1e-13  2e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3499, Training Accuracy: 0.8250\n",
      "Training model for class 7...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.3704e+03 -2.4835e+04  1e+05  3e+00  3e-12\n",
      " 1: -1.5772e+03 -1.5597e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.3565e+03 -7.2775e+03  1e+04  1e-01  2e-12\n",
      " 3: -1.2795e+03 -4.7758e+03  5e+03  7e-02  1e-12\n",
      " 4: -1.2380e+03 -3.3719e+03  3e+03  3e-02  1e-12\n",
      " 5: -1.2375e+03 -2.5550e+03  2e+03  2e-02  1e-12\n",
      " 6: -1.2499e+03 -2.0421e+03  1e+03  8e-03  1e-12\n",
      " 7: -1.2689e+03 -1.7784e+03  6e+02  4e-03  1e-12\n",
      " 8: -1.2986e+03 -1.5936e+03  3e+02  2e-03  1e-12\n",
      " 9: -1.3108e+03 -1.5156e+03  2e+02  8e-04  2e-12\n",
      "10: -1.3281e+03 -1.4575e+03  1e+02  4e-04  1e-12\n",
      "11: -1.3379e+03 -1.4160e+03  8e+01  9e-05  2e-12\n",
      "12: -1.3478e+03 -1.3969e+03  5e+01  4e-05  2e-12\n",
      "13: -1.3552e+03 -1.3825e+03  3e+01  8e-06  2e-12\n",
      "14: -1.3604e+03 -1.3749e+03  1e+01  3e-06  2e-12\n",
      "15: -1.3628e+03 -1.3714e+03  9e+00  1e-06  2e-12\n",
      "16: -1.3648e+03 -1.3688e+03  4e+00  3e-07  2e-12\n",
      "17: -1.3656e+03 -1.3678e+03  2e+00  4e-08  2e-12\n",
      "18: -1.3662e+03 -1.3670e+03  8e-01  1e-08  2e-12\n",
      "19: -1.3665e+03 -1.3667e+03  2e-01  2e-09  2e-12\n",
      "20: -1.3666e+03 -1.3666e+03  6e-02  2e-10  2e-12\n",
      "21: -1.3666e+03 -1.3666e+03  2e-02  6e-11  2e-12\n",
      "22: -1.3666e+03 -1.3666e+03  4e-03  1e-11  2e-12\n",
      "23: -1.3666e+03 -1.3666e+03  2e-04  4e-13  2e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3424, Training Accuracy: 0.8288\n",
      "Training model for class 8...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1221e+03 -2.3344e+04  1e+05  3e+00  3e-12\n",
      " 1: -1.4326e+03 -1.4406e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.2310e+03 -7.1307e+03  1e+04  2e-01  2e-12\n",
      " 3: -1.1446e+03 -4.7495e+03  6e+03  8e-02  2e-12\n",
      " 4: -1.0802e+03 -3.3533e+03  4e+03  4e-02  2e-12\n",
      " 5: -1.0547e+03 -2.2953e+03  2e+03  2e-02  2e-12\n",
      " 6: -1.0425e+03 -2.0198e+03  1e+03  1e-02  2e-12\n",
      " 7: -1.0501e+03 -1.5684e+03  7e+02  6e-03  2e-12\n",
      " 8: -1.0566e+03 -1.3794e+03  4e+02  2e-03  2e-12\n",
      " 9: -1.0815e+03 -1.2498e+03  2e+02  9e-04  2e-12\n",
      "10: -1.0927e+03 -1.1946e+03  1e+02  3e-04  2e-12\n",
      "11: -1.1024e+03 -1.1622e+03  6e+01  1e-04  2e-12\n",
      "12: -1.1073e+03 -1.1497e+03  4e+01  4e-05  2e-12\n",
      "13: -1.1137e+03 -1.1373e+03  2e+01  2e-06  2e-12\n",
      "14: -1.1174e+03 -1.1324e+03  2e+01  8e-07  2e-12\n",
      "15: -1.1214e+03 -1.1273e+03  6e+00  2e-07  2e-12\n",
      "16: -1.1231e+03 -1.1252e+03  2e+00  4e-08  2e-12\n",
      "17: -1.1237e+03 -1.1244e+03  7e-01  8e-09  2e-12\n",
      "18: -1.1240e+03 -1.1241e+03  1e-01  1e-10  2e-12\n",
      "19: -1.1240e+03 -1.1240e+03  3e-02  3e-11  2e-12\n",
      "20: -1.1240e+03 -1.1240e+03  2e-03  1e-12  2e-12\n",
      "21: -1.1240e+03 -1.1240e+03  2e-04  1e-13  2e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3514, Training Accuracy: 0.8243\n",
      "Training model for class 9...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.2782e+03 -2.3259e+04  1e+05  3e+00  3e-12\n",
      " 1: -1.5385e+03 -1.4516e+04  3e+04  4e-01  3e-12\n",
      " 2: -1.3471e+03 -7.1815e+03  1e+04  1e-01  2e-12\n",
      " 3: -1.2773e+03 -4.5813e+03  5e+03  7e-02  2e-12\n",
      " 4: -1.2443e+03 -3.3040e+03  3e+03  4e-02  2e-12\n",
      " 5: -1.2350e+03 -2.7434e+03  2e+03  3e-02  2e-12\n",
      " 6: -1.2337e+03 -2.1318e+03  1e+03  1e-02  2e-12\n",
      " 7: -1.2261e+03 -1.9422e+03  9e+02  7e-03  2e-12\n",
      " 8: -1.2098e+03 -1.8678e+03  8e+02  5e-03  2e-12\n",
      " 9: -1.2538e+03 -1.5957e+03  4e+02  2e-03  2e-12\n",
      "10: -1.2704e+03 -1.5032e+03  3e+02  1e-03  2e-12\n",
      "11: -1.2872e+03 -1.4258e+03  1e+02  3e-04  2e-12\n",
      "12: -1.3015e+03 -1.3865e+03  9e+01  1e-04  2e-12\n",
      "13: -1.3117e+03 -1.3631e+03  5e+01  5e-05  2e-12\n",
      "14: -1.3177e+03 -1.3511e+03  3e+01  2e-05  2e-12\n",
      "15: -1.3239e+03 -1.3418e+03  2e+01  7e-06  2e-12\n",
      "16: -1.3266e+03 -1.3374e+03  1e+01  2e-06  2e-12\n",
      "17: -1.3290e+03 -1.3342e+03  5e+00  9e-07  2e-12\n",
      "18: -1.3302e+03 -1.3326e+03  2e+00  3e-07  2e-12\n",
      "19: -1.3310e+03 -1.3316e+03  6e-01  5e-08  2e-12\n",
      "20: -1.3312e+03 -1.3314e+03  3e-01  3e-14  3e-12\n",
      "21: -1.3313e+03 -1.3313e+03  8e-02  2e-14  2e-12\n",
      "22: -1.3313e+03 -1.3313e+03  2e-02  4e-14  3e-12\n",
      "23: -1.3313e+03 -1.3313e+03  8e-04  2e-16  3e-12\n",
      "Optimal solution found.\n",
      "Training Loss: 0.3471, Training Accuracy: 0.8265\n"
     ]
    }
   ],
   "source": [
    "# sub-sample the training set\n",
    "indices = np.random.choice(range(features_train.shape[0]), size=10000, replace=False)\n",
    "sub_features_train = features_train[indices]\n",
    "sub_y_train = y_train[indices]\n",
    "\n",
    "\n",
    "svm_models = []\n",
    "num_classes = 10\n",
    "for class_idx in range(num_classes):\n",
    "    print(f\"Training model for class {class_idx}...\")\n",
    "    \n",
    "    # Convert the labels to binary\n",
    "    binary_y_train = np.where(sub_y_train == class_idx, 1, -1)\n",
    "    \n",
    "    # Train the model\n",
    "    svm_model = KernelSVM(kernel='linear', C=1.0)\n",
    "    loss, acc = svm_model.fit(sub_features_train, binary_y_train)\n",
    "    \n",
    "    # Store the model\n",
    "    svm_models.append(svm_model)\n",
    "    \n",
    "    print(f\"Training Loss: {loss:.4f}, Training Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model for class 0...\n",
      "Predicting with model for class 1...\n",
      "Predicting with model for class 2...\n",
      "Predicting with model for class 3...\n",
      "Predicting with model for class 4...\n",
      "Predicting with model for class 5...\n",
      "Predicting with model for class 6...\n",
      "Predicting with model for class 7...\n",
      "Predicting with model for class 8...\n",
      "Predicting with model for class 9...\n",
      "Test Accuracy: 0.4681\n"
     ]
    }
   ],
   "source": [
    "# initialize decision function values\n",
    "decision_function_values = np.zeros((features_test.shape[0], num_classes))\n",
    "\n",
    "# use each SVM model to predict the decision function values\n",
    "for class_idx, svm_model in enumerate(svm_models):\n",
    "    print(f\"Predicting with model for class {class_idx}...\")\n",
    "    decision_values = svm_model.predict(features_test)\n",
    "    decision_function_values[:, class_idx] = decision_values\n",
    "\n",
    "# select the class with the maximum decision function value\n",
    "y_pred = np.argmax(decision_function_values, axis=1)\n",
    "\n",
    "# calculate the test accuracy\n",
    "test_accuracy = accuracy(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(range(features_train.shape[0]), size=10000, replace=False)\n",
    "sub_features_train = features_train[indices]\n",
    "sub_y_train = y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Original Features): 0.6799\n",
      "Test Accuracy (Original Features): 0.6095\n"
     ]
    }
   ],
   "source": [
    "# train a linear SVM model using the sklearn library on original features\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1.0)\n",
    "svm.fit(features_train, y_train)\n",
    "\n",
    "# get the training accuracy\n",
    "y_pred_train = svm.predict(features_train)\n",
    "train_accuracy = accuracy(y_train, y_pred_train)\n",
    "print(f\"Training Accuracy (Original Features): {train_accuracy:.4f}\")\n",
    "\n",
    "# get the test accuracy\n",
    "y_pred_test = svm.predict(features_test)\n",
    "test_accuracy = accuracy(y_test, y_pred_test)\n",
    "print(f\"Test Accuracy (Original Features): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for class 0...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7871e+02 -4.7591e+04  1e+05  6e-01  1e-12\n",
      " 1: -8.7357e+01 -1.6363e+04  3e+04  1e-01  1e-12\n",
      " 2:  7.1424e+01 -2.8786e+03  5e+03  1e-02  6e-13\n",
      " 3:  3.4034e+01 -4.3417e+02  7e+02  2e-03  1e-13\n",
      " 4:  1.4387e+01 -1.0893e+02  2e+02  4e-04  3e-14\n",
      " 5:  3.1241e+00 -8.4993e+00  1e+01  2e-06  2e-14\n",
      " 6: -2.9156e-01 -2.0520e+00  2e+00  1e-07  8e-15\n",
      " 7: -7.0476e-01 -1.4958e+00  8e-01  4e-08  5e-15\n",
      " 8: -9.2682e-01 -1.2625e+00  3e-01  5e-09  5e-15\n",
      " 9: -1.0051e+00 -1.1178e+00  1e-01  1e-09  6e-15\n",
      "10: -1.0382e+00 -1.0567e+00  2e-02  2e-16  6e-15\n",
      "11: -1.0447e+00 -1.0461e+00  1e-03  2e-16  5e-15\n",
      "12: -1.0452e+00 -1.0452e+00  3e-05  2e-16  5e-15\n",
      "13: -1.0452e+00 -1.0452e+00  6e-07  2e-16  6e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.8048, Training Accuracy: 0.5976\n",
      "Training model for class 1...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.5386e+02 -6.1069e+04  2e+05  8e-01  2e-12\n",
      " 1: -2.4507e+02 -2.4188e+04  5e+04  2e-01  1e-12\n",
      " 2:  9.4807e+00 -1.2396e+04  2e+04  8e-02  8e-13\n",
      " 3:  1.3649e+02 -2.8502e+03  4e+03  1e-02  4e-13\n",
      " 4:  6.8764e+01 -7.1436e+02  1e+03  2e-03  1e-13\n",
      " 5:  2.1639e+01 -8.7727e+01  1e+02  1e-04  4e-14\n",
      " 6:  1.2758e+00 -9.3089e+00  1e+01  1e-06  2e-14\n",
      " 7: -1.4371e+00 -4.5523e+00  3e+00  3e-07  1e-14\n",
      " 8: -2.0614e+00 -3.6298e+00  2e+00  1e-07  9e-15\n",
      " 9: -2.4954e+00 -3.2620e+00  8e-01  2e-08  9e-15\n",
      "10: -2.7054e+00 -2.8257e+00  1e-01  9e-10  9e-15\n",
      "11: -2.7398e+00 -2.7597e+00  2e-02  1e-10  9e-15\n",
      "12: -2.7458e+00 -2.7489e+00  3e-03  2e-11  1e-14\n",
      "13: -2.7468e+00 -2.7469e+00  9e-05  4e-13  9e-15\n",
      "14: -2.7469e+00 -2.7469e+00  2e-06  5e-15  1e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.7455, Training Accuracy: 0.6273\n",
      "Training model for class 2...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8792e+02 -5.3743e+04  1e+05  7e-01  2e-12\n",
      " 1: -2.5742e+02 -2.0001e+04  4e+04  1e-01  1e-12\n",
      " 2:  2.7429e+01 -9.1167e+03  2e+04  6e-02  7e-13\n",
      " 3:  1.6076e+02 -4.4493e+03  7e+03  2e-02  4e-13\n",
      " 4:  8.7835e+01 -8.2718e+02  1e+03  2e-03  1e-13\n",
      " 5:  3.0753e+01 -1.5658e+02  2e+02  3e-04  5e-14\n",
      " 6:  3.2052e+00 -1.7963e+01  2e+01  9e-07  3e-14\n",
      " 7: -1.7091e+00 -7.0984e+00  5e+00  2e-07  1e-14\n",
      " 8: -2.9196e+00 -5.1153e+00  2e+00  5e-08  1e-14\n",
      " 9: -3.4774e+00 -4.3091e+00  8e-01  1e-08  1e-14\n",
      "10: -3.6856e+00 -3.9419e+00  3e-01  1e-09  1e-14\n",
      "11: -3.7610e+00 -3.7915e+00  3e-02  1e-11  1e-14\n",
      "12: -3.7713e+00 -3.7724e+00  1e-03  3e-13  1e-14\n",
      "13: -3.7717e+00 -3.7718e+00  3e-05  7e-15  1e-14\n",
      "14: -3.7717e+00 -3.7717e+00  9e-07  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.6527, Training Accuracy: 0.6737\n",
      "Training model for class 3...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.4007e+02 -6.5898e+04  2e+05  8e-01  2e-12\n",
      " 1: -4.0544e+02 -2.9386e+04  6e+04  2e-01  1e-12\n",
      " 2: -9.3724e+00 -1.5872e+04  3e+04  9e-02  8e-13\n",
      " 3:  2.0085e+02 -3.6613e+03  6e+03  1e-02  5e-13\n",
      " 4:  1.0540e+02 -9.1702e+02  1e+03  2e-03  1e-13\n",
      " 5:  3.3196e+01 -1.3155e+02  2e+02  1e-04  5e-14\n",
      " 6:  8.1142e-01 -1.4501e+01  2e+01  1e-06  3e-14\n",
      " 7: -3.0563e+00 -7.8696e+00  5e+00  3e-07  1e-14\n",
      " 8: -4.3430e+00 -6.3731e+00  2e+00  9e-08  1e-14\n",
      " 9: -4.9880e+00 -5.6953e+00  7e-01  2e-15  2e-14\n",
      "10: -5.1528e+00 -5.2769e+00  1e-01  1e-15  1e-14\n",
      "11: -5.1884e+00 -5.1949e+00  7e-03  3e-16  2e-14\n",
      "12: -5.1905e+00 -5.1908e+00  3e-04  3e-15  1e-14\n",
      "13: -5.1906e+00 -5.1906e+00  7e-06  2e-16  2e-14\n",
      "14: -5.1906e+00 -5.1906e+00  1e-07  1e-15  1e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.6825, Training Accuracy: 0.6588\n",
      "Training model for class 4...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.9754e+02 -6.2821e+04  2e+05  8e-01  2e-12\n",
      " 1: -4.1062e+02 -2.6592e+04  5e+04  2e-01  1e-12\n",
      " 2:  1.2170e+00 -1.1543e+04  2e+04  7e-02  8e-13\n",
      " 3:  1.7665e+02 -4.2934e+03  7e+03  1e-02  5e-13\n",
      " 4:  9.4456e+01 -1.0669e+03  2e+03  3e-03  1e-13\n",
      " 5:  4.4265e+01 -3.0866e+02  4e+02  4e-04  7e-14\n",
      " 6:  5.4199e+00 -2.2706e+01  3e+01  5e-06  4e-14\n",
      " 7: -1.9382e+00 -8.8729e+00  7e+00  1e-06  2e-14\n",
      " 8: -3.8791e+00 -6.2940e+00  2e+00  3e-07  2e-14\n",
      " 9: -4.6957e+00 -5.5278e+00  8e-01  1e-08  2e-14\n",
      "10: -4.9112e+00 -5.0505e+00  1e-01  2e-16  2e-14\n",
      "11: -4.9556e+00 -4.9637e+00  8e-03  6e-16  2e-14\n",
      "12: -4.9584e+00 -4.9587e+00  2e-04  9e-16  2e-14\n",
      "13: -4.9585e+00 -4.9585e+00  5e-06  2e-16  2e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.7186, Training Accuracy: 0.6407\n",
      "Training model for class 5...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8423e+02 -5.7691e+04  2e+05  7e-01  1e-12\n",
      " 1: -3.1865e+02 -2.2309e+04  4e+04  2e-01  1e-12\n",
      " 2:  2.6265e+01 -1.1620e+04  2e+04  7e-02  7e-13\n",
      " 3:  1.9937e+02 -4.7960e+03  7e+03  1e-02  3e-13\n",
      " 4:  1.0449e+02 -1.1562e+03  2e+03  2e-03  9e-14\n",
      " 5:  3.7312e+01 -2.3989e+02  3e+02  4e-04  4e-14\n",
      " 6:  7.0304e+00 -3.4668e+01  4e+01  2e-16  3e-14\n",
      " 7: -1.0177e+00 -9.9680e+00  9e+00  8e-16  1e-14\n",
      " 8: -2.7667e+00 -6.1512e+00  3e+00  2e-16  1e-14\n",
      " 9: -3.5389e+00 -4.7365e+00  1e+00  3e-16  1e-14\n",
      "10: -3.8195e+00 -4.1654e+00  3e-01  2e-16  1e-14\n",
      "11: -3.9092e+00 -3.9611e+00  5e-02  2e-16  1e-14\n",
      "12: -3.9249e+00 -3.9276e+00  3e-03  2e-16  1e-14\n",
      "13: -3.9257e+00 -3.9258e+00  4e-05  7e-16  1e-14\n",
      "14: -3.9258e+00 -3.9258e+00  7e-07  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.8329, Training Accuracy: 0.5835\n",
      "Training model for class 6...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7176e+02 -5.3380e+04  1e+05  7e-01  1e-12\n",
      " 1: -2.1944e+02 -1.9096e+04  4e+04  1e-01  1e-12\n",
      " 2:  3.6786e+01 -7.8510e+03  1e+04  5e-02  7e-13\n",
      " 3:  7.3057e+01 -1.5454e+03  3e+03  7e-03  3e-13\n",
      " 4:  3.2555e+01 -3.3413e+02  5e+02  1e-03  8e-14\n",
      " 5:  1.1992e+01 -8.4403e+01  1e+02  2e-04  3e-14\n",
      " 6:  1.0008e+00 -8.5568e+00  1e+01  2e-16  2e-14\n",
      " 7: -1.4310e+00 -3.6854e+00  2e+00  2e-16  1e-14\n",
      " 8: -2.0682e+00 -3.1042e+00  1e+00  2e-16  8e-15\n",
      " 9: -2.3007e+00 -2.6938e+00  4e-01  4e-16  8e-15\n",
      "10: -2.3896e+00 -2.5496e+00  2e-01  4e-16  9e-15\n",
      "11: -2.4336e+00 -2.4648e+00  3e-02  2e-16  8e-15\n",
      "12: -2.4442e+00 -2.4452e+00  1e-03  2e-16  1e-14\n",
      "13: -2.4446e+00 -2.4446e+00  1e-05  2e-16  1e-14\n",
      "14: -2.4446e+00 -2.4446e+00  2e-07  6e-16  1e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.6663, Training Accuracy: 0.6669\n",
      "Training model for class 7...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.9409e+02 -5.5869e+04  2e+05  7e-01  2e-12\n",
      " 1: -2.0561e+02 -2.0055e+04  4e+04  1e-01  1e-12\n",
      " 2:  4.1330e+01 -9.3974e+03  2e+04  6e-02  7e-13\n",
      " 3:  9.6130e+01 -1.5900e+03  3e+03  8e-03  3e-13\n",
      " 4:  4.7505e+01 -4.2722e+02  7e+02  2e-03  9e-14\n",
      " 5:  1.7798e+01 -1.0453e+02  1e+02  2e-04  4e-14\n",
      " 6:  2.1306e+00 -1.2006e+01  1e+01  4e-16  2e-14\n",
      " 7: -1.0797e+00 -5.0138e+00  4e+00  3e-16  1e-14\n",
      " 8: -2.0696e+00 -3.3472e+00  1e+00  5e-16  8e-15\n",
      " 9: -2.3576e+00 -2.8580e+00  5e-01  2e-16  9e-15\n",
      "10: -2.4969e+00 -2.5921e+00  1e-01  9e-16  1e-14\n",
      "11: -2.5273e+00 -2.5344e+00  7e-03  7e-16  1e-14\n",
      "12: -2.5298e+00 -2.5299e+00  2e-04  5e-16  1e-14\n",
      "13: -2.5298e+00 -2.5299e+00  2e-06  2e-16  1e-14\n",
      "Optimal solution found.\n",
      "Training Loss: 0.7564, Training Accuracy: 0.6218\n",
      "Training model for class 8...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7404e+02 -5.6518e+04  2e+05  7e-01  1e-12\n",
      " 1: -1.5866e+02 -1.9080e+04  4e+04  1e-01  1e-12\n",
      " 2:  5.0354e+01 -7.1838e+03  1e+04  4e-02  6e-13\n",
      " 3:  5.9533e+01 -1.3199e+03  2e+03  7e-03  2e-13\n",
      " 4:  3.0974e+01 -2.7262e+02  4e+02  1e-03  6e-14\n",
      " 5:  9.8146e+00 -2.9580e+01  4e+01  6e-06  2e-14\n",
      " 6:  3.7633e-01 -4.7490e+00  5e+00  3e-07  1e-14\n",
      " 7: -8.5547e-01 -2.6653e+00  2e+00  4e-08  6e-15\n",
      " 8: -1.2004e+00 -1.9686e+00  8e-01  1e-08  5e-15\n",
      " 9: -1.3808e+00 -1.6537e+00  3e-01  3e-16  6e-15\n",
      "10: -1.4529e+00 -1.4829e+00  3e-02  3e-16  6e-15\n",
      "11: -1.4630e+00 -1.4640e+00  1e-03  2e-16  6e-15\n",
      "12: -1.4634e+00 -1.4634e+00  3e-05  3e-16  6e-15\n",
      "13: -1.4634e+00 -1.4634e+00  6e-07  2e-16  6e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.7851, Training Accuracy: 0.6075\n",
      "Training model for class 9...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.4061e+02 -5.4978e+04  1e+05  7e-01  1e-12\n",
      " 1: -2.4948e+02 -2.0989e+04  4e+04  1e-01  1e-12\n",
      " 2:  3.5843e+00 -9.8428e+03  2e+04  6e-02  7e-13\n",
      " 3:  9.0566e+01 -2.1251e+03  4e+03  1e-02  3e-13\n",
      " 4:  4.7905e+01 -5.5449e+02  8e+02  2e-03  1e-13\n",
      " 5:  1.7248e+01 -9.7127e+01  1e+02  2e-04  4e-14\n",
      " 6:  2.0122e+00 -1.1924e+01  1e+01  5e-16  2e-14\n",
      " 7: -1.2032e+00 -4.4588e+00  3e+00  5e-16  1e-14\n",
      " 8: -1.9327e+00 -3.2676e+00  1e+00  2e-16  8e-15\n",
      " 9: -2.3078e+00 -2.8009e+00  5e-01  2e-16  9e-15\n",
      "10: -2.4469e+00 -2.5653e+00  1e-01  2e-16  9e-15\n",
      "11: -2.4845e+00 -2.4988e+00  1e-02  6e-16  9e-15\n",
      "12: -2.4896e+00 -2.4902e+00  5e-04  9e-16  9e-15\n",
      "13: -2.4898e+00 -2.4898e+00  1e-05  2e-16  9e-15\n",
      "14: -2.4898e+00 -2.4898e+00  5e-07  1e-15  9e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.7738, Training Accuracy: 0.6131\n",
      "Predicting with model for class 0...\n",
      "Predicting with model for class 1...\n",
      "Predicting with model for class 2...\n",
      "Predicting with model for class 3...\n",
      "Predicting with model for class 4...\n",
      "Predicting with model for class 5...\n",
      "Predicting with model for class 6...\n",
      "Predicting with model for class 7...\n",
      "Predicting with model for class 8...\n",
      "Predicting with model for class 9...\n",
      "Test Accuracy: 0.1504\n"
     ]
    }
   ],
   "source": [
    "svm_models = []\n",
    "num_classes = 10\n",
    "for class_idx in range(num_classes):\n",
    "    print(f\"Training model for class {class_idx}...\")\n",
    "    \n",
    "    # Convert the labels to binary\n",
    "    binary_y_train = np.where(sub_y_train == class_idx, 1, -1)\n",
    "    \n",
    "    # Train the model\n",
    "    svm_model = KernelSVM(kernel='polynomial', C=10)\n",
    "    loss, acc = svm_model.fit(sub_features_train, binary_y_train)\n",
    "    \n",
    "    # Store the model\n",
    "    svm_models.append(svm_model)\n",
    "    \n",
    "    print(f\"Training Loss: {loss:.4f}, Training Accuracy: {acc:.4f}\")\n",
    "\n",
    "# initialize decision function values\n",
    "decision_function_values = np.zeros((features_test.shape[0], num_classes))\n",
    "\n",
    "# use each SVM model to predict the decision function values\n",
    "for class_idx, svm_model in enumerate(svm_models):\n",
    "    print(f\"Predicting with model for class {class_idx}...\")\n",
    "    decision_values = svm_model.predict(features_test)\n",
    "    decision_function_values[:, class_idx] = decision_values\n",
    "\n",
    "# select the class with the maximum decision function value\n",
    "y_pred = np.argmax(decision_function_values, axis=1)\n",
    "\n",
    "# calculate the test accuracy\n",
    "test_accuracy = accuracy(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for class 0...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8630e+01 -1.7953e+01  6e+03  8e+01  1e-13\n",
      " 1: -2.0013e+00 -1.7733e+01  2e+02  2e+00  1e-13\n",
      " 2: -9.3555e-01 -1.3308e+01  3e+01  2e-01  1e-14\n",
      " 3: -6.4153e-01 -5.2196e+00  7e+00  4e-02  4e-15\n",
      " 4: -5.4011e-01 -1.7706e+00  2e+00  8e-03  2e-15\n",
      " 5: -5.7599e-01 -9.3022e-01  4e-01  2e-03  2e-15\n",
      " 6: -6.0903e-01 -7.1187e-01  1e-01  2e-04  2e-15\n",
      " 7: -6.2894e-01 -6.5497e-01  3e-02  6e-17  2e-15\n",
      " 8: -6.3704e-01 -6.3997e-01  3e-03  6e-17  2e-15\n",
      " 9: -6.3813e-01 -6.3829e-01  2e-04  6e-17  2e-15\n",
      "10: -6.3819e-01 -6.3819e-01  2e-06  7e-17  2e-15\n",
      "11: -6.3819e-01 -6.3819e-01  3e-08  6e-17  2e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.1800, Training Accuracy: 0.9100\n",
      "Training model for class 1...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.4610e+01 -1.9386e+01  7e+03  8e+01  1e-13\n",
      " 1: -2.5517e+00 -1.9172e+01  1e+02  1e+00  2e-13\n",
      " 2: -1.3997e+00 -1.3444e+01  2e+01  2e-01  2e-14\n",
      " 3: -1.0380e+00 -5.7152e+00  7e+00  4e-02  5e-15\n",
      " 4: -9.3789e-01 -2.0880e+00  1e+00  6e-03  3e-15\n",
      " 5: -1.0116e+00 -1.4656e+00  5e-01  1e-03  2e-15\n",
      " 6: -1.0682e+00 -1.2099e+00  1e-01  2e-04  2e-15\n",
      " 7: -1.0995e+00 -1.1196e+00  2e-02  3e-06  3e-15\n",
      " 8: -1.1055e+00 -1.1086e+00  3e-03  4e-07  2e-15\n",
      " 9: -1.1066e+00 -1.1068e+00  2e-04  1e-08  3e-15\n",
      "10: -1.1067e+00 -1.1067e+00  4e-06  1e-10  3e-15\n",
      "11: -1.1067e+00 -1.1067e+00  5e-08  2e-12  3e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.2380, Training Accuracy: 0.8810\n",
      "Training model for class 2...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.8284e+01 -2.0761e+01  8e+03  9e+01  2e-13\n",
      " 1: -2.9948e+00 -2.0534e+01  2e+02  2e+00  1e-13\n",
      " 2: -1.4390e+00 -1.5167e+01  3e+01  2e-01  1e-14\n",
      " 3: -1.0535e+00 -6.1096e+00  7e+00  3e-02  3e-15\n",
      " 4: -1.0158e+00 -2.4319e+00  2e+00  5e-03  3e-15\n",
      " 5: -1.1115e+00 -1.5973e+00  5e-01  1e-03  2e-15\n",
      " 6: -1.1704e+00 -1.3352e+00  2e-01  1e-04  3e-15\n",
      " 7: -1.2042e+00 -1.2369e+00  3e-02  5e-06  3e-15\n",
      " 8: -1.2120e+00 -1.2199e+00  8e-03  6e-17  3e-15\n",
      " 9: -1.2146e+00 -1.2153e+00  6e-04  6e-17  3e-15\n",
      "10: -1.2149e+00 -1.2149e+00  1e-05  6e-17  3e-15\n",
      "11: -1.2149e+00 -1.2149e+00  2e-07  7e-17  3e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.1960, Training Accuracy: 0.9020\n",
      "Training model for class 3...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.2102e+01 -2.0623e+01  7e+03  9e+01  2e-13\n",
      " 1: -2.9858e+00 -2.0414e+01  1e+02  1e+00  2e-13\n",
      " 2: -1.6211e+00 -1.4019e+01  2e+01  1e-01  2e-14\n",
      " 3: -1.2851e+00 -6.2577e+00  7e+00  4e-02  5e-15\n",
      " 4: -1.2493e+00 -2.4441e+00  1e+00  5e-03  2e-15\n",
      " 5: -1.3406e+00 -1.8024e+00  5e-01  1e-03  2e-15\n",
      " 6: -1.4061e+00 -1.5283e+00  1e-01  1e-04  2e-15\n",
      " 7: -1.4325e+00 -1.4575e+00  3e-02  1e-05  3e-15\n",
      " 8: -1.4397e+00 -1.4424e+00  3e-03  6e-07  3e-15\n",
      " 9: -1.4406e+00 -1.4407e+00  2e-04  3e-08  3e-15\n",
      "10: -1.4406e+00 -1.4406e+00  7e-06  1e-09  3e-15\n",
      "11: -1.4406e+00 -1.4406e+00  2e-07  2e-11  3e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.2140, Training Accuracy: 0.8930\n",
      "Training model for class 4...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.7330e+01 -1.9104e+01  6e+03  8e+01  2e-13\n",
      " 1: -2.6873e+00 -1.8903e+01  1e+02  1e+00  2e-13\n",
      " 2: -1.5215e+00 -1.2292e+01  2e+01  1e-01  2e-14\n",
      " 3: -1.1969e+00 -5.5610e+00  6e+00  3e-02  5e-15\n",
      " 4: -1.1313e+00 -2.2781e+00  1e+00  4e-03  3e-15\n",
      " 5: -1.2390e+00 -1.6053e+00  4e-01  8e-04  3e-15\n",
      " 6: -1.2969e+00 -1.4043e+00  1e-01  1e-04  3e-15\n",
      " 7: -1.3212e+00 -1.3420e+00  2e-02  8e-06  3e-15\n",
      " 8: -1.3276e+00 -1.3297e+00  2e-03  7e-07  3e-15\n",
      " 9: -1.3283e+00 -1.3285e+00  2e-04  4e-08  3e-15\n",
      "10: -1.3284e+00 -1.3284e+00  7e-06  2e-09  3e-15\n",
      "11: -1.3284e+00 -1.3284e+00  1e-07  2e-11  3e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.2140, Training Accuracy: 0.8930\n",
      "Training model for class 5...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.7409e+01 -2.0311e+01  7e+03  9e+01  1e-13\n",
      " 1: -2.7480e+00 -2.0097e+01  2e+02  2e+00  1e-13\n",
      " 2: -1.4405e+00 -1.4599e+01  3e+01  2e-01  2e-14\n",
      " 3: -1.0785e+00 -6.1275e+00  7e+00  4e-02  4e-15\n",
      " 4: -1.0374e+00 -2.5110e+00  2e+00  8e-03  3e-15\n",
      " 5: -1.1086e+00 -1.5476e+00  5e-01  1e-03  4e-15\n",
      " 6: -1.1666e+00 -1.3221e+00  2e-01  3e-04  2e-15\n",
      " 7: -1.1945e+00 -1.2311e+00  4e-02  6e-17  3e-15\n",
      " 8: -1.2043e+00 -1.2117e+00  7e-03  6e-17  2e-15\n",
      " 9: -1.2066e+00 -1.2074e+00  8e-04  6e-17  2e-15\n",
      "10: -1.2069e+00 -1.2069e+00  2e-05  6e-17  3e-15\n",
      "11: -1.2069e+00 -1.2069e+00  4e-07  1e-16  3e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.2120, Training Accuracy: 0.8940\n",
      "Training model for class 6...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.6304e+01 -1.8517e+01  6e+03  8e+01  1e-13\n",
      " 1: -2.2008e+00 -1.8301e+01  1e+02  1e+00  1e-13\n",
      " 2: -1.1693e+00 -1.2277e+01  2e+01  1e-01  2e-14\n",
      " 3: -8.9438e-01 -5.1724e+00  6e+00  4e-02  4e-15\n",
      " 4: -8.2426e-01 -1.9586e+00  1e+00  6e-03  2e-15\n",
      " 5: -8.7903e-01 -1.1976e+00  4e-01  1e-03  2e-15\n",
      " 6: -9.1715e-01 -1.0228e+00  1e-01  3e-04  2e-15\n",
      " 7: -9.3643e-01 -9.6090e-01  2e-02  6e-17  2e-15\n",
      " 8: -9.4445e-01 -9.4701e-01  3e-03  6e-17  2e-15\n",
      " 9: -9.4543e-01 -9.4552e-01  8e-05  7e-17  2e-15\n",
      "10: -9.4547e-01 -9.4547e-01  1e-06  2e-16  2e-15\n",
      "11: -9.4547e-01 -9.4547e-01  2e-08  2e-16  2e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.1740, Training Accuracy: 0.9130\n",
      "Training model for class 7...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.9810e+01 -1.9951e+01  7e+03  8e+01  1e-13\n",
      " 1: -2.4091e+00 -1.9709e+01  1e+02  1e+00  1e-13\n",
      " 2: -1.3306e+00 -1.3671e+01  3e+01  2e-01  2e-14\n",
      " 3: -9.7337e-01 -5.8395e+00  7e+00  4e-02  5e-15\n",
      " 4: -8.7488e-01 -2.1822e+00  2e+00  7e-03  2e-15\n",
      " 5: -9.5314e-01 -1.3271e+00  4e-01  9e-04  2e-15\n",
      " 6: -1.0161e+00 -1.1192e+00  1e-01  1e-04  2e-15\n",
      " 7: -1.0406e+00 -1.0613e+00  2e-02  9e-06  2e-15\n",
      " 8: -1.0467e+00 -1.0498e+00  3e-03  1e-06  3e-15\n",
      " 9: -1.0478e+00 -1.0479e+00  1e-04  3e-08  3e-15\n",
      "10: -1.0478e+00 -1.0478e+00  5e-06  1e-09  3e-15\n",
      "11: -1.0478e+00 -1.0478e+00  8e-08  2e-11  3e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.1880, Training Accuracy: 0.9060\n",
      "Training model for class 8...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.8031e+01 -1.8231e+01  6e+03  8e+01  1e-13\n",
      " 1: -2.1570e+00 -1.7989e+01  1e+02  2e+00  1e-13\n",
      " 2: -1.1249e+00 -1.2668e+01  2e+01  2e-01  1e-14\n",
      " 3: -8.2548e-01 -5.5510e+00  7e+00  5e-02  4e-15\n",
      " 4: -6.7875e-01 -1.9231e+00  1e+00  7e-03  2e-15\n",
      " 5: -7.2927e-01 -1.2679e+00  6e-01  2e-03  2e-15\n",
      " 6: -7.8651e-01 -9.0595e-01  1e-01  7e-05  2e-15\n",
      " 7: -8.1252e-01 -8.4528e-01  3e-02  9e-06  2e-15\n",
      " 8: -8.2166e-01 -8.2658e-01  5e-03  7e-08  2e-15\n",
      " 9: -8.2331e-01 -8.2384e-01  5e-04  7e-09  2e-15\n",
      "10: -8.2351e-01 -8.2352e-01  1e-05  2e-10  2e-15\n",
      "11: -8.2351e-01 -8.2351e-01  3e-07  3e-12  2e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.1920, Training Accuracy: 0.9040\n",
      "Training model for class 9...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.3083e+01 -1.9802e+01  7e+03  8e+01  1e-13\n",
      " 1: -2.6180e+00 -1.9591e+01  2e+02  2e+00  1e-13\n",
      " 2: -1.3444e+00 -1.4066e+01  3e+01  2e-01  1e-14\n",
      " 3: -9.9005e-01 -5.9213e+00  7e+00  4e-02  4e-15\n",
      " 4: -9.1173e-01 -2.1256e+00  1e+00  6e-03  2e-15\n",
      " 5: -9.8721e-01 -1.3482e+00  4e-01  1e-03  2e-15\n",
      " 6: -1.0371e+00 -1.1619e+00  1e-01  2e-04  3e-15\n",
      " 7: -1.0622e+00 -1.0927e+00  3e-02  6e-17  3e-15\n",
      " 8: -1.0709e+00 -1.0768e+00  6e-03  6e-17  2e-15\n",
      " 9: -1.0729e+00 -1.0733e+00  4e-04  6e-17  2e-15\n",
      "10: -1.0731e+00 -1.0731e+00  1e-05  8e-17  3e-15\n",
      "11: -1.0731e+00 -1.0731e+00  3e-07  6e-17  2e-15\n",
      "Optimal solution found.\n",
      "Training Loss: 0.1920, Training Accuracy: 0.9040\n",
      "Predicting with model for class 0...\n",
      "Predicting with model for class 1...\n",
      "Predicting with model for class 2...\n",
      "Predicting with model for class 3...\n",
      "Predicting with model for class 4...\n",
      "Predicting with model for class 5...\n",
      "Predicting with model for class 6...\n",
      "Predicting with model for class 7...\n",
      "Predicting with model for class 8...\n",
      "Predicting with model for class 9...\n",
      "Test Accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "svm_models = []\n",
    "num_classes = 10\n",
    "for class_idx in range(num_classes):\n",
    "    print(f\"Training model for class {class_idx}...\")\n",
    "    \n",
    "    # Convert the labels to binary\n",
    "    binary_y_train = np.where(sub_y_train == class_idx, 1, -1)\n",
    "    \n",
    "    # Train the model\n",
    "    svm_model = KernelSVM(kernel='rbf', C=0.01)\n",
    "    loss, acc = svm_model.fit(sub_features_train, binary_y_train)\n",
    "    \n",
    "    # Store the model\n",
    "    svm_models.append(svm_model)\n",
    "    \n",
    "    print(f\"Training Loss: {loss:.4f}, Training Accuracy: {acc:.4f}\")\n",
    "\n",
    "# initialize decision function values\n",
    "decision_function_values = np.zeros((features_test.shape[0], num_classes))\n",
    "\n",
    "# use each SVM model to predict the decision function values\n",
    "for class_idx, svm_model in enumerate(svm_models):\n",
    "    print(f\"Predicting with model for class {class_idx}...\")\n",
    "    decision_values = svm_model.predict(features_test)\n",
    "    decision_function_values[:, class_idx] = decision_values\n",
    "\n",
    "# select the class with the maximum decision function value\n",
    "y_pred = np.argmax(decision_function_values, axis=1)\n",
    "\n",
    "# calculate the test accuracy\n",
    "test_accuracy = accuracy(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
